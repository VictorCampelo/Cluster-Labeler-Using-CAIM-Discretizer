{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAIBAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpi84g6f6hotn9W8mftpcb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorCampelo/Cluster-Labeler-Using-CAIM-Discretizer/blob/master/CAIBAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vohh86sTY1Ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e71042bc-c2ac-4148-9406-1a862ac56e42"
      },
      "source": [
        "!pip3 install caimcaim\n",
        "!pip3 install kneed\n",
        "!pip3 install sklearn -U"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: caimcaim in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from caimcaim) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from caimcaim) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->caimcaim) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->caimcaim) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->caimcaim) (1.4.1)\n",
            "Requirement already satisfied: kneed in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from kneed) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from kneed) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from kneed) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->kneed) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->kneed) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->kneed) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->kneed) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->kneed) (1.15.0)\n",
            "Requirement already up-to-date: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugHa3GpqDwNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-VGOr1-3WhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the libraries\n",
        "from caimcaim import CAIMD\n",
        "from itertools import compress \n",
        "from kneed import KneeLocator\n",
        "from itertools import cycle, islice\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, MeanShift, \\\n",
        "estimate_bandwidth, SpectralClustering, AgglomerativeClustering, Birch\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from yellowbrick.cluster import InterclusterDistance\n",
        "\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
        "from sklearn.metrics import homogeneity_completeness_v_measure\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from itertools import cycle"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6St8nimph1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the Iris dataset with pandas\n",
        "iris = load_iris()\n",
        "digt = load_digits()\n",
        "wine = load_wine()\n",
        "canc = load_breast_cancer()\n",
        "\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_digt = pd.DataFrame(digt.data)\n",
        "df_wine = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "df_canc = pd.DataFrame(canc.data, columns=canc.feature_names)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc1e-0ExsDzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3fbd99e1-041d-40aa-f9fc-402fa94c7a81"
      },
      "source": [
        "df_iris.head()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                5.1               3.5                1.4               0.2\n",
              "1                4.9               3.0                1.4               0.2\n",
              "2                4.7               3.2                1.3               0.2\n",
              "3                4.6               3.1                1.5               0.2\n",
              "4                5.0               3.6                1.4               0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPIwOXMrsl1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "102a8879-f832-4efb-f766-06dd3c489ed8"
      },
      "source": [
        "df_digt.head()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2     3     4     5    6   ...   57   58    59    60    61   62   63\n",
              "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  ...  0.0  6.0  13.0  10.0   0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  ...  0.0  0.0  11.0  16.0  10.0  0.0  0.0\n",
              "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  ...  0.0  0.0   3.0  11.0  16.0  9.0  0.0\n",
              "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  ...  0.0  7.0  13.0  13.0   9.0  0.0  0.0\n",
              "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  ...  0.0  0.0   2.0  16.0   4.0  0.0  0.0\n",
              "\n",
              "[5 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMz-9x1Espxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "cfd3a32f-659c-447a-e997-48783557e235"
      },
      "source": [
        "df_wine.head()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0    14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1    13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2    13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3    14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4    13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioTwoQIhswu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "f1b1439f-0468-4d1e-be66-a156f8b96095"
      },
      "source": [
        "df_canc.head()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycmJCqBDZUe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcess(X):\n",
        "  # Standardize data\n",
        "  # Normalizing the Data\n",
        "  scaler = StandardScaler()\n",
        "  # scaler = MinMaxScaler()\n",
        "  return normalize(scaler.fit_transform(X))"
      ],
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym8lHZ0HZvD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PCARedution(X):\n",
        "  # Reducing the dimensions of the data \n",
        "  pca = PCA(n_components = 3) \n",
        "  X1 = pca.fit_transform(X)\n",
        "  return X1"
      ],
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZoxqvxHYfLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Elbow_kneeLocator(X):\n",
        "  clusters = []\n",
        "  best_n_clusters = 0\n",
        "  best_sil = 0\n",
        "  for i in range(1, 11):\n",
        "      km = KMeans(n_clusters=i).fit(X)\n",
        "      clusters.append(km.inertia_)\n",
        "      labels = km.labels_\n",
        "      if len(set(labels)) <= 1: continue\n",
        "      sil = silhouette_score(X, labels)\n",
        "      if sil > best_sil:\n",
        "        best_sil = sil\n",
        "        best_n_clusters = i\n",
        "      \n",
        "  fig, ax = plt.subplots()\n",
        "  sns.lineplot(x=list(range(1, 11)), y=clusters, ax=ax)\n",
        "  ax.set_title('Searching for Elbow')\n",
        "  ax.set_xlabel('Clusters')\n",
        "  ax.set_ylabel('Inertia')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  kl = KneeLocator(range(1, 11), \n",
        "                   clusters, \n",
        "                   curve=\"convex\", \n",
        "                   direction=\"decreasing\")\n",
        "  print(\"\\nResult finding by Knee Locator function: \")\n",
        "  print(kl.elbow)\n",
        "  print(\"\\n\")\n",
        "  return best_n_clusters"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK3YivEKazey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringKmeans(X, n_c):\n",
        "  if n_c == 0:\n",
        "    clusters = []\n",
        "    best_n_clusters = 0\n",
        "    best_sil = 0\n",
        "    for i in range(1, 11):\n",
        "        km = KMeans(n_clusters=i).fit(X)\n",
        "        clusters.append(km.inertia_)\n",
        "        labels = km.labels_\n",
        "        if len(set(labels)) <= 1: continue\n",
        "        sil = calinski_harabasz_score(X, labels)\n",
        "        # sil = silhouette_score(X, labels)\n",
        "        if sil > best_sil:\n",
        "          best_sil = sil\n",
        "          best_n_clusters = i\n",
        "    n_c = best_n_clusters\n",
        "\n",
        "  model = KMeans(n_clusters=n_c).fit(X)\n",
        "  \n",
        "  for cluster in unique(model.labels_):\n",
        "    row_ix = where(model.labels_ == cluster)\n",
        "    plt.scatter(X[row_ix, 0], X[row_ix, 1], s=200)\n",
        "\n",
        "  plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[:, 1],\n",
        "              marker='*', s=300,\n",
        "              c='r', label='centroid')\n",
        "  plt.show()\n",
        "  return model.labels_, n_c"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmCM8JfCOl92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringAffinityPropagation(X):\n",
        "  pref = [-1,-2,-3,-4,-5,-6,-7,-8,-9,-10]\n",
        "  best_pref = 0\n",
        "  best_sil = 0\n",
        "  for i in pref:\n",
        "    model = AffinityPropagation(preference=i, max_iter=500).fit(X)\n",
        "    cluster_centers_indices = model.cluster_centers_indices_\n",
        "    labels = model.labels_\n",
        "\n",
        "    if len(set(labels)) <= 1 or len(set(labels)) > len(X)-1: continue\n",
        "    sil = calinski_harabasz_score(X, labels)\n",
        "    # sil = silhouette_score(X, labels, metric='sqeuclidean')\n",
        "    if sil > best_sil:\n",
        "      best_sil = sil\n",
        "      best_pref = i\n",
        "\n",
        "  model = AffinityPropagation(preference=best_pref, max_iter=500).fit(X)\n",
        "  cluster_centers_indices = model.cluster_centers_indices_\n",
        "  labels = model.labels_\n",
        "\n",
        "  n_clusters_ = len(cluster_centers_indices)\n",
        "\n",
        "  print('Estimated number of clusters: %d' % n_clusters_)\n",
        "  \n",
        "  colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "  for k, col in zip(range(n_clusters_), colors):\n",
        "      class_members = labels == k\n",
        "      cluster_center = X[cluster_centers_indices[k]]\n",
        "      plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
        "      plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
        "              markeredgecolor='k', markersize=14)\n",
        "      for x in X[class_members]:\n",
        "          plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
        "\n",
        "  plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, n_clusters_"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXYA_RaIA3TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringAgglomerativeClustering (X, n_c):\n",
        "  best_n_cluster = 0\n",
        "  best_sil = 0\n",
        "  if n_c == 0:\n",
        "    for i in range(1, 11):\n",
        "      model = AgglomerativeClustering(n_clusters=i).fit(X)\n",
        "      labels = model.labels_\n",
        "\n",
        "      if len(set(labels)) <= 1: continue\n",
        "      sil = calinski_harabasz_score(X, labels)\n",
        "      # sil = silhouette_score(X, labels, metric='sqeuclidean')\n",
        "      if sil > best_sil:\n",
        "        best_sil = sil\n",
        "        best_n_cluster = i\n",
        "\n",
        "    model = AgglomerativeClustering(n_clusters=best_n_cluster).fit(X)\n",
        "    labels = model.labels_\n",
        "\n",
        "    n_clusters_ = model.n_clusters_\n",
        "\n",
        "    print('Estimated number of clusters: %d' % n_clusters_)\n",
        "  else:\n",
        "    model = AgglomerativeClustering(n_clusters=n_c).fit(X)\n",
        "    labels = model.labels_\n",
        "\n",
        "    n_clusters_ = model.n_clusters_\n",
        "  \n",
        "  colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "  for k, col in zip(range(n_clusters_), colors):\n",
        "      class_members = labels == k\n",
        "      plt.scatter(X[class_members, 0], X[class_members, 1], s=200, c=col)\n",
        "      # plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
        "\n",
        "  plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, n_clusters_"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaSF3nfsI9_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringMeanShift(X):\n",
        "  best_band = 0\n",
        "  best_sil = 0\n",
        "  quant = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "  for i in quant:\n",
        "    bandwidth = estimate_bandwidth(X, quantile=i) # Manually set the quantile to get num clusters = 3\n",
        "\n",
        "    model = MeanShift(bandwidth=bandwidth).fit(X)\n",
        "    labels = model.labels_\n",
        "    cluster_centers = model.cluster_centers_\n",
        "\n",
        "    labels_unique = np.unique(labels)\n",
        "    n_clusters_ = len(labels_unique)\n",
        "\n",
        "    if len(set(labels)) <= 1: continue\n",
        "    sil = calinski_harabasz_score(X, labels)\n",
        "    # sil = silhouette_score(X, labels, metric='sqeuclidean')\n",
        "    if sil > best_sil:\n",
        "      best_sil = sil\n",
        "      best_band = bandwidth\n",
        "\n",
        "  model = MeanShift(bandwidth=best_band, bin_seeding=True).fit(X)\n",
        "  labels = model.labels_\n",
        "  cluster_centers = model.cluster_centers_\n",
        "\n",
        "  labels_unique = np.unique(labels)\n",
        "  n_clusters_ = len(labels_unique)\n",
        "\n",
        "  print('Estimated number of clusters: %d' % n_clusters_)\n",
        "  \n",
        "  colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "  for k, col in zip(range(n_clusters_), colors):\n",
        "      class_members = labels == k\n",
        "      plt.scatter(X[class_members, 0], X[class_members, 1], s=200, c=col)\n",
        "      # plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
        "\n",
        "  plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, n_clusters_"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw4OAMllN4Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringSpectralClustering(X, n_c):\n",
        "  best_n_clusters = 0\n",
        "  best_sil = 0\n",
        "  if n_c == 0:\n",
        "    for i in range(1,11):\n",
        "      model = SpectralClustering(n_clusters=i, random_state=0).fit(X)\n",
        "      labels = model.labels_\n",
        "\n",
        "      labels_unique = np.unique(labels)\n",
        "      n_clusters_ = len(labels_unique)\n",
        "\n",
        "      if len(set(labels)) <= 1: continue\n",
        "      sil = calinski_harabasz_score(X, labels)\n",
        "      # sil = silhouette_score(X, labels, metric='sqeuclidean')\n",
        "      if sil > best_sil:\n",
        "        best_sil = sil\n",
        "        best_n_clusters = i\n",
        "\n",
        "    model = SpectralClustering(n_clusters=best_n_clusters, random_state=0).fit(X)\n",
        "    labels = model.labels_\n",
        "\n",
        "    labels_unique = np.unique(labels)\n",
        "    n_clusters_ = len(labels_unique)\n",
        "\n",
        "    print('Estimated number of clusters: %d' % n_clusters_)\n",
        "  else:\n",
        "    model = SpectralClustering(n_clusters=n_c, random_state=0).fit(X)\n",
        "    labels = model.labels_\n",
        "    labels_unique = np.unique(labels)\n",
        "    n_clusters_ = len(labels_unique)\n",
        "  \n",
        "  colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "  for k, col in zip(range(n_clusters_), colors):\n",
        "      class_members = labels == k\n",
        "      plt.scatter(X[class_members, 0], X[class_members, 1], s=200, c=col)\n",
        "      # plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
        "\n",
        "  plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, n_clusters_"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er21BfKuy5i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringBirch(X, n_c):\n",
        "  best_n_clusters = 0\n",
        "  best_sil = 0\n",
        "  if n_c == 0:\n",
        "    for i in range(1,11):\n",
        "      model = Birch(n_clusters = i).fit(X)\n",
        "      labels = model.labels_\n",
        "\n",
        "      labels_unique = np.unique(labels)\n",
        "      n_clusters_ = len(labels_unique)\n",
        "\n",
        "      if len(set(labels)) <= 1: continue\n",
        "      sil = calinski_harabasz_score(X, labels)\n",
        "      # sil = silhouette_score(X, labels, metric='sqeuclidean')\n",
        "      if sil > best_sil:\n",
        "        best_sil = sil\n",
        "        best_n_clusters = i\n",
        "\n",
        "    model = Birch(n_clusters = best_n_clusters).fit(X)\n",
        "    labels = model.labels_\n",
        "\n",
        "    labels_unique = np.unique(labels)\n",
        "    n_clusters_ = len(labels_unique)\n",
        "\n",
        "    print('Estimated number of clusters: %d' % n_clusters_)\n",
        "  else:\n",
        "    model = Birch(n_clusters = n_c).fit(X)\n",
        "    labels = model.labels_\n",
        "    labels_unique = np.unique(labels)\n",
        "    n_clusters_ = len(labels_unique)\n",
        "\n",
        "  colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "  for k, col in zip(range(n_clusters_), colors):\n",
        "      class_members = labels == k\n",
        "      plt.scatter(X[class_members, 0], X[class_members, 1], s=200, c=col)\n",
        "      # plt.plot(X[class_members, 0], X[class_members, 1], col + '.')\n",
        "\n",
        "  plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, n_clusters_"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlwP2eoCj5Ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clusteringDBSCAN(X):\n",
        "  epss = [0.001, 0.01, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.23, 0.27, 0.3, 0.33, 0.37, \n",
        "          0.4, 0.43, 0.47, 0.5, 0.53, 0.57, 0.6]\n",
        "  best_sil = 0\n",
        "  best_eps = 0\n",
        "  for eps in epss:\n",
        "    model = DBSCAN(eps=eps).fit(X)\n",
        "    core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\n",
        "    core_samples_mask[model.core_sample_indices_] = True\n",
        "    labels = model.labels_\n",
        "\n",
        "    # Number of clusters in labels, ignoring noise if present.\n",
        "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise_ = list(labels).count(-1)\n",
        "    if len(set(labels)) <= 1: continue\n",
        "    sil = calinski_harabasz_score(X, labels)\n",
        "    # sil = silhouette_score(X, labels)\n",
        "    if sil > best_sil:\n",
        "      best_sil = sil\n",
        "      best_eps = eps\n",
        "  print(best_eps)\n",
        "  min_samples = [1,2,3,4,5,6,7,8,9,10]\n",
        "  best_min_sa = 0\n",
        "  best_sil = 0\n",
        "  for i in min_samples:\n",
        "    model = DBSCAN(eps=best_eps, min_samples=i).fit(X)\n",
        "    core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\n",
        "    core_samples_mask[model.core_sample_indices_] = True\n",
        "    labels = model.labels_\n",
        "\n",
        "    # Number of clusters in labels, ignoring noise if present.\n",
        "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise_ = list(labels).count(-1)\n",
        "\n",
        "    if len(set(labels)) <= 1: continue\n",
        "    sil = calinski_harabasz_score(X, labels)\n",
        "    # sil = silhouette_score(X, labels)\n",
        "    if sil > best_sil:\n",
        "      best_sil = sil\n",
        "      best_min_sa = i\n",
        "  \n",
        "  model = DBSCAN(eps=best_eps, min_samples=best_min_sa).fit(X)\n",
        "  core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\n",
        "  core_samples_mask[model.core_sample_indices_] = True\n",
        "  labels = model.labels_\n",
        "\n",
        "  # Number of clusters in labels, ignoring noise if present.\n",
        "  n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "  n_noise_ = list(labels).count(-1)\n",
        "  \n",
        "  unique_labels = set(labels)\n",
        "  colors = [plt.cm.Spectral(each)\n",
        "            for each in np.linspace(0, 1, len(unique_labels))]\n",
        "  for k, col in zip(unique_labels, colors):\n",
        "      if k == -1:\n",
        "          # Black used for noise.\n",
        "          col = [0, 0, 0, 1]\n",
        "\n",
        "      class_member_mask = (labels == k)\n",
        "\n",
        "      xy = X[class_member_mask & core_samples_mask]\n",
        "      plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "              markeredgecolor='k', markersize=14)\n",
        "\n",
        "      xy = X[class_member_mask & ~core_samples_mask]\n",
        "      plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "              markeredgecolor='k', markersize=6)\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "  return model.labels_, len(set(labels))"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Lf-kPdcbpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caim(df, target):\n",
        "  caim = CAIMD()\n",
        "  caim.fit(df, target)\n",
        "\n",
        "  print(\"\\nCaim splited scheme: \")\n",
        "  print(caim.split_scheme)\n",
        "  print()\n",
        "\n",
        "  return caim.split_scheme"
      ],
      "execution_count": 533,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_X-oN-JztTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clustersAtrGenerate(labels, splited_sheme, type, n_clusters_kl):\n",
        "  cluster_x_atr = {}\n",
        "  for num_cluster in range(len(unique(labels))):\n",
        "    cluster_x_atr[num_cluster] = []\n",
        "  for i, fx in enumerate(splited_sheme):\n",
        "    zone = []\n",
        "    res = list(zip(splited_sheme[fx], splited_sheme[fx][1:] + splited_sheme[fx][:1]))\n",
        "    res.pop()\n",
        "    # # print(res)\n",
        "    # # if type == 1 or type == 5 or type == 6:\n",
        "    # if type == 99:\n",
        "    #   for j, zones in enumerate(res):\n",
        "    #     if (j+1) >= n_clusters_kl:\n",
        "    #       cluster_x_atr[0].append(zones)\n",
        "    #       continue  \n",
        "    #     cluster_x_atr[j+1].append(zones)\n",
        "    # else: \n",
        "    for j, zones in enumerate(res):\n",
        "      cluster_x_atr[j].append(zones)\n",
        "  print(\"Range of values ​​by clusters obtained by the CAIM method\")\n",
        "  print(cluster_x_atr)\n",
        "  print(\"\\n\")\n",
        "  return cluster_x_atr"
      ],
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs6kZivz2D1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_perc(labels, df, cluster_x_atr):\n",
        "  cluster = []\n",
        "  for i, num_cluster in enumerate(range(len(unique(labels)))):\n",
        "    number_entries = len(df[df['target'] == num_cluster])\n",
        "    perc = []\n",
        "    print(\"cluster %s\" % i)\n",
        "    if number_entries < 1: continue\n",
        "\n",
        "    #columns\n",
        "    for l, entry in enumerate(df):\n",
        "      if entry == 'target': continue\n",
        "      #lines\n",
        "      count = 0\n",
        "      k = 0\n",
        "      for j, cl in enumerate(range(len(unique(labels)))):\n",
        "        max = 0\n",
        "        for row in df[df['target'] == num_cluster][entry]:\n",
        "          if row >= cluster_x_atr[j][l][0] and \\\n",
        "          row <= cluster_x_atr[j][l][1]:\n",
        "            max += 1\n",
        "        \n",
        "        if max > count:\n",
        "          count = max\n",
        "          k = j\n",
        "      perc.append([round((count/number_entries)*100), cluster_x_atr[k][l], \n",
        "                  number_entries, number_entries-count])\n",
        "      print(perc[l][0], perc[l][1], perc[l][2], perc[l][3])\n",
        "    cluster.append(perc)\n",
        "  print(\"Accuracy of each attribute in each cluster\")\n",
        "  print(cluster)\n",
        "  print()\n",
        "  return cluster"
      ],
      "execution_count": 653,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrbEFKEX2h8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standard_method(perc_atr_by_cluster, names):\n",
        "  #standard\n",
        "  print(\"Labels by Standard Method: \")\n",
        "  list_label_standard = []\n",
        "  for i, v1 in enumerate(perc_atr_by_cluster):\n",
        "    print('Cluster %s' % i)\n",
        "    rot = \"\"\n",
        "    base = 0\n",
        "    j = 1\n",
        "    params = [\"Attribute name\", \"Accuracy\", \"Interval\", \"Number of elements\", \\\n",
        "              \"Erro\"] \n",
        "    rot_dict = dict.fromkeys(params, None)\n",
        "\n",
        "    for porc_interval, name in zip(v1, names):\n",
        "      if porc_interval[0] >= base:\n",
        "        rot_dict[\"Attribute name\"] = name\n",
        "        rot_dict[\"Accuracy\"] = porc_interval[0]\n",
        "        rot_dict[\"Interval\"] = porc_interval[1]\n",
        "        rot_dict[\"Number of elements\"] = porc_interval[2]\n",
        "        rot_dict[\"Erro\"] = porc_interval[3]\n",
        "        rot = \"(Attribute name: \" +name + \\\n",
        "              \" Interval: \"+str(porc_interval[1]) + \")\"\n",
        "        if j <= len(porc_interval):\n",
        "          rot += \" - \"\n",
        "        base = porc_interval[0]\n",
        "    \n",
        "    print(\"Attribute name: \" +rot_dict[\"Attribute name\"] +\", Accuracy: \"+ \\\n",
        "          str(rot_dict[\"Accuracy\"])+\"%,\"+ \" Interval: \"+str(rot_dict[\"Interval\"])+ \\\n",
        "          \", Number of elements: \" + str(rot_dict[\"Number of elements\"]) + \\\n",
        "          \", Erro: \" + str(rot_dict[\"Erro\"]))\n",
        "    list_label_standard.append(rot)\n",
        "  print(\"\\n\")\n",
        "  return list_label_standard"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05b_iG__20xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alternative_method(perc_atr_by_cluster, names, var):\n",
        "  #alternative\n",
        "  print(\"Labels by Alternative Method: \")\n",
        "  list_label_alternative = []\n",
        "  for i, v1 in enumerate(perc_atr_by_cluster):\n",
        "    print('Cluster %s' % i)\n",
        "    base = 0\n",
        "    for porc_interval, name in zip(v1, names):\n",
        "      if porc_interval[0] >= base:\n",
        "        base = porc_interval[0]\n",
        "    rot = \"\"\n",
        "    j = 1\n",
        "    for porc_interval, name in zip(v1, names):\n",
        "      if porc_interval[0] >= (base-var):\n",
        "        print(\"Attribute name: \" +name +\", Accuracy: \"+ str(porc_interval[0])+\"%,\"+\\\n",
        "        \" Interval: \"+str(porc_interval[1])+ \", Number of elements: \" \\\n",
        "        + str(porc_interval[2]) + \", Erro: \" + str(porc_interval[3]))\n",
        "        \n",
        "        rot = \"(Attribute name: \" +name + \" Interval: \"+str(porc_interval[1]) + \")\"\n",
        "\n",
        "        if j <= len(porc_interval):\n",
        "          rot += \" - \"\n",
        "    list_label_alternative.append(rot)\n",
        "  print(\"\\n\")\n",
        "  return list_label_alternative"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27525wu83Sln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def result2df(df, list_label_standard, list_label_alternative):\n",
        "  stand = []\n",
        "  alter = []\n",
        "\n",
        "  for i, row in df.iterrows():\n",
        "    stand.append(list_label_standard[int(row[\"target\"])]) \n",
        "    alter.append(list_label_alternative[int(row[\"target\"])])\n",
        "\n",
        "  df['label_CAIBAL_standard'] = stand\n",
        "  df['label_CAIBAL_alternative'] = alter\n",
        "\n",
        "  return df"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhHcIhAFnwE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_labels(labels, labels_set):\n",
        "  corr_labels = []\n",
        "\n",
        "  for i, lb in enumerate(labels):\n",
        "    j = list(labels_set).index(lb)\n",
        "    corr_labels.append(j)\n",
        "\n",
        "  return corr_labels"
      ],
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xly3mwDKU5oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caibal(df, type_cluster, discretization_type, var, n_clusters, prepro, is_sklearn_df, has_target):\n",
        "  # X.data, X.target, X.feature_names\n",
        "  # caibal(X, cluster_alg, discretization_type, var, n_clusters, prepro, is_sklearn_df, has_target)\n",
        "  \n",
        "  if has_target:\n",
        "    target = df.target\n",
        "\n",
        "  if is_sklearn_df:\n",
        "    names = df.feature_names\n",
        "    X = df.data\n",
        "    df = pd.DataFrame(X)\n",
        "  else:\n",
        "    X = df.values\n",
        "    names = df.columns\n",
        "   \n",
        "  if prepro:\n",
        "    df = preProcess(df)\n",
        "    # X = PCARedution(X)\n",
        "\n",
        "  if type_cluster == 1:\n",
        "    # np.random.seed(0)\n",
        "    # if n_clusters == 0:\n",
        "    #   n_clusters = Elbow_kneeLocator(X)\n",
        "    labels, n_clusters = clusteringKmeans(X, n_clusters)\n",
        "\n",
        "    # print(target)\n",
        "    # print(labels)\n",
        "    # labels_set = df.target.unique()\n",
        "    # print(labels_set)\n",
        "    # # df['target'] = correct_labels(labels, labels_set)\n",
        "\n",
        "    # print(df['target'].values)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "\n",
        "  elif type_cluster == 2:\n",
        "    labels, n_clusters = clusteringAffinityPropagation(X)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "\n",
        "  elif type_cluster == 3:\n",
        "    labels, n_clusters = clusteringDBSCAN(X)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "  \n",
        "  elif type_cluster == 4:\n",
        "    labels, n_clusters = clusteringAgglomerativeClustering(X, n_clusters)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "  \n",
        "  elif type_cluster == 5:\n",
        "    np.random.seed(0)\n",
        "    labels, n_clusters = clusteringMeanShift(X)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "  \n",
        "  elif type_cluster == 6:\n",
        "    np.random.seed(0)\n",
        "    labels, n_clusters = clusteringSpectralClustering(X, n_clusters)\n",
        "    splited_sheme = caim(df.values, labels)\n",
        "    df['target'] = labels\n",
        "    cluster_x_atr = clustersAtrGenerate(df.target, splited_sheme, type_cluster, n_clusters)\n",
        "\n",
        "    print(cluster_x_atr)\n",
        "\n",
        "    if has_target == 1:\n",
        "      print(\"Accuracy:\")\n",
        "      print(homogeneity_completeness_v_measure(target, df['target'], beta=1.0))\n",
        "      print(\"\\n\")\n",
        "\n",
        "  perc_atr_by_cluster = calc_perc(labels, df, cluster_x_atr)\n",
        "\n",
        "  if discretization_type == 1:\n",
        "    result = standard_method(perc_atr_by_cluster, names)\n",
        "  else: \n",
        "    result = alternative_method(perc_atr_by_cluster, names, var)\n",
        "  \n",
        "  # return result2df(df, list_label_standard, list_label_alternative)"
      ],
      "execution_count": 660,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ej9tstqUXLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6402cef1-359b-4851-ba8f-0a3689542c8a"
      },
      "source": [
        "resp = int(input(\"Use external CSV file (1) or load sklearn datasets (2): \"))\n",
        "is_sklearn_df = False\n",
        "if resp == 1:\n",
        "  has_target = int(input(\"This csv file has a target column?(1 - Yes, 0 - No): \"))\n",
        "  path = input(\"Enter with the path file: \")\n",
        "  index = int(input(\"This csv file has a index columns?(1 - Yes, 0 - No):\"))\n",
        "  if index:\n",
        "    index_col = input(\"Enter with the name of index column: \")\n",
        "    df = pd.read_csv(path, index_col=index)\n",
        "  else:\n",
        "    df = pd.read_csv(path)\n",
        "else:\n",
        "  has_target = 1\n",
        "  is_sklearn_df = True\n",
        "  print(\"1 - Iris\\n2 - Wine\\n3 - Breast Cancer\")\n",
        "  resp = int(input(\"Select Dataset: \"))\n",
        "  if resp == 1:\n",
        "    df = load_iris()\n",
        "  elif resp == 2:\n",
        "    df = load_wine()\n",
        "  else:\n",
        "    df = load_breast_cancer()\n",
        "  \n",
        "  # print(df.DESCR)\n",
        "\n",
        "print(\"1 - Kmeans\\n2 - Affinity Propagation\\n3 - DBSCAN\\n4 - Agglomerative Clustering\\n\\\n",
        "5 - Mean shift\\n6 - Spectral Clustering\")\n",
        "cluster_alg = int(input(\"Choise the clustering algorithm: \"))\n",
        "n_clusters = 0\n",
        "if cluster_alg == 1 or cluster_alg == 4 or cluster_alg == 6:\n",
        "  auto_n_cluster = int(input(\"Desire set manually the number of clusters? (1 - Yes, 0 - No) \"))\n",
        "  if auto_n_cluster == 1:\n",
        "    n_clusters = int(input(\"Enter with the number of clusters: \"))\n",
        "\n",
        "discretization_type = int(input(\"1 - Pattern Method\\n2 - Alternative Method: \"))\n",
        "var = 0\n",
        "if discretization_type == 2:\n",
        "  var = int(input(\"Type the varience value: \"))\n",
        "\n",
        "prepro = int(input(\"Wish standarnize data? (1 - Yes, 0 - No) \"))\n",
        "\n",
        "# DATAFRAME, CLUSTER TYPE, VAR. MIN, NUMBER OF CLUSTER, APPLY PREPROCESSING.\n",
        "caibal(df, cluster_alg, discretization_type, var, n_clusters, prepro, is_sklearn_df, has_target)"
      ],
      "execution_count": 668,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use external CSV file (1) or load sklearn datasets (2): 1\n",
            "This csv file has a target column?(1 - Yes, 0 - No): 0\n",
            "Enter with the path file: /content/seedsData_original.csv\n",
            "This csv file has a index columns?(1 - Yes, 0 - No):0\n",
            "1 - Kmeans\n",
            "2 - Affinity Propagation\n",
            "3 - DBSCAN\n",
            "4 - Agglomerative Clustering\n",
            "5 - Mean shift\n",
            "6 - Spectral Clustering\n",
            "Choise the clustering algorithm: 1\n",
            "Desire set manually the number of clusters? (1 - Yes, 0 - No) 1\n",
            "Enter with the number of clusters: 3\n",
            "1 - Pattern Method\n",
            "2 - Alternative Method: 1\n",
            "Wish standarnize data? (1 - Yes, 0 - No) 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Categorical [7]\n",
            "# 0  GLOBAL CAIM  54.994086239524194\n",
            "# 1  GLOBAL CAIM  55.721777576428735\n",
            "# 2  GLOBAL CAIM  69.33898305084746\n",
            "# 3  GLOBAL CAIM  55.105500550055005\n",
            "# 4  GLOBAL CAIM  54.994818652849744\n",
            "# 5  GLOBAL CAIM  55.037837837837834\n",
            "# 6  GLOBAL CAIM  55.059985041136876\n",
            "\n",
            "Caim splited scheme: \n",
            "{0: [10.59, 12.79, 12.8, 21.18], 1: [12.41, 12.72, 13.83, 17.25], 2: [0.8081, 0.8831, 0.9183, 905.0], 3: [4.899, 4.981, 5.046, 6.675], 4: [2.63, 2.716, 2.717, 4.033], 5: [0.7651, 1.955, 8.456, 903.0], 6: [4.519, 4.805, 4.828, 6.55]}\n",
            "\n",
            "Range of values ​​by clusters obtained by the CAIM method\n",
            "{0: [(10.59, 12.79), (12.41, 12.72), (0.8081, 0.8831), (4.899, 4.981), (2.63, 2.716), (0.7651, 1.955), (4.519, 4.805)], 1: [(12.79, 12.8), (12.72, 13.83), (0.8831, 0.9183), (4.981, 5.046), (2.716, 2.717), (1.955, 8.456), (4.805, 4.828)], 2: [(12.8, 21.18), (13.83, 17.25), (0.9183, 905.0), (5.046, 6.675), (2.717, 4.033), (8.456, 903.0), (4.828, 6.55)]}\n",
            "\n",
            "\n",
            "{0: [(10.59, 12.79), (12.41, 12.72), (0.8081, 0.8831), (4.899, 4.981), (2.63, 2.716), (0.7651, 1.955), (4.519, 4.805)], 1: [(12.79, 12.8), (12.72, 13.83), (0.8831, 0.9183), (4.981, 5.046), (2.716, 2.717), (1.955, 8.456), (4.805, 4.828)], 2: [(12.8, 21.18), (13.83, 17.25), (0.9183, 905.0), (5.046, 6.675), (2.717, 4.033), (8.456, 903.0), (4.828, 6.55)]}\n",
            "cluster 0\n",
            "64 (12.8, 21.18) 185 67\n",
            "60 (13.83, 17.25) 185 74\n",
            "69 (0.8081, 0.8831) 185 58\n",
            "98 (5.046, 6.675) 185 4\n",
            "91 (2.717, 4.033) 185 16\n",
            "88 (1.955, 8.456) 185 23\n",
            "92 (4.828, 6.55) 185 14\n",
            "cluster 1\n",
            "79 (12.8, 21.18) 24 5\n",
            "75 (13.83, 17.25) 24 6\n",
            "100 (0.9183, 905.0) 24 0\n",
            "88 (5.046, 6.675) 24 3\n",
            "100 (2.717, 4.033) 24 0\n",
            "100 (1.955, 8.456) 24 0\n",
            "83 (4.828, 6.55) 24 4\n",
            "cluster 2\n",
            "100 (12.8, 21.18) 1 0\n",
            "100 (13.83, 17.25) 1 0\n",
            "100 (0.8831, 0.9183) 1 0\n",
            "100 (5.046, 6.675) 1 0\n",
            "100 (2.717, 4.033) 1 0\n",
            "100 (8.456, 903.0) 1 0\n",
            "100 (4.828, 6.55) 1 0\n",
            "Accuracy of each attribute in each cluster\n",
            "[[[64, (12.8, 21.18), 185, 67], [60, (13.83, 17.25), 185, 74], [69, (0.8081, 0.8831), 185, 58], [98, (5.046, 6.675), 185, 4], [91, (2.717, 4.033), 185, 16], [88, (1.955, 8.456), 185, 23], [92, (4.828, 6.55), 185, 14]], [[79, (12.8, 21.18), 24, 5], [75, (13.83, 17.25), 24, 6], [100, (0.9183, 905.0), 24, 0], [88, (5.046, 6.675), 24, 3], [100, (2.717, 4.033), 24, 0], [100, (1.955, 8.456), 24, 0], [83, (4.828, 6.55), 24, 4]], [[100, (12.8, 21.18), 1, 0], [100, (13.83, 17.25), 1, 0], [100, (0.8831, 0.9183), 1, 0], [100, (5.046, 6.675), 1, 0], [100, (2.717, 4.033), 1, 0], [100, (8.456, 903.0), 1, 0], [100, (4.828, 6.55), 1, 0]]]\n",
            "\n",
            "Labels by Standard Method: \n",
            "Cluster 0\n",
            "Attribute name: V4, Accuracy: 98%, Interval: (5.046, 6.675), Number of elements: 185, Erro: 4\n",
            "Cluster 1\n",
            "Attribute name: V6, Accuracy: 100%, Interval: (1.955, 8.456), Number of elements: 24, Erro: 0\n",
            "Cluster 2\n",
            "Attribute name: V7, Accuracy: 100%, Interval: (4.828, 6.55), Number of elements: 1, Erro: 0\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZePQAf2VKQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "918ddf35-166a-448d-d07e-a9e1b353e78c"
      },
      "source": [
        "df = pd.read_csv('/content/seedsData_original.csv')\n",
        "df"
      ],
      "execution_count": 663,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.26</td>\n",
              "      <td>14.84</td>\n",
              "      <td>871.0000</td>\n",
              "      <td>5.763</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.221</td>\n",
              "      <td>5.220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>905.0000</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>12.19</td>\n",
              "      <td>13.20</td>\n",
              "      <td>0.8783</td>\n",
              "      <td>5.137</td>\n",
              "      <td>2.981</td>\n",
              "      <td>3.631</td>\n",
              "      <td>4.870</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>11.23</td>\n",
              "      <td>12.88</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>5.140</td>\n",
              "      <td>2.795</td>\n",
              "      <td>4.325</td>\n",
              "      <td>5.003</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>13.20</td>\n",
              "      <td>13.66</td>\n",
              "      <td>0.8883</td>\n",
              "      <td>5.236</td>\n",
              "      <td>3.232</td>\n",
              "      <td>8.315</td>\n",
              "      <td>5.056</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>11.84</td>\n",
              "      <td>13.21</td>\n",
              "      <td>0.8521</td>\n",
              "      <td>5.175</td>\n",
              "      <td>2.836</td>\n",
              "      <td>3.598</td>\n",
              "      <td>5.044</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>12.30</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.8684</td>\n",
              "      <td>5.243</td>\n",
              "      <td>2.974</td>\n",
              "      <td>5.637</td>\n",
              "      <td>5.063</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>210 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        V1     V2        V3     V4     V5     V6     V7  target\n",
              "0    15.26  14.84  871.0000  5.763  3.312  2.221  5.220       1\n",
              "1    14.88  14.57    0.8811  5.554  3.333  1.018  4.956       1\n",
              "2    14.29  14.09  905.0000  5.291  3.337  2.699  4.825       1\n",
              "3    13.84  13.94    0.8955  5.324  3.379  2.259  4.805       1\n",
              "4    16.14  14.99    0.9034  5.658  3.562  1.355  5.175       1\n",
              "..     ...    ...       ...    ...    ...    ...    ...     ...\n",
              "205  12.19  13.20    0.8783  5.137  2.981  3.631  4.870       3\n",
              "206  11.23  12.88    0.8511  5.140  2.795  4.325  5.003       3\n",
              "207  13.20  13.66    0.8883  5.236  3.232  8.315  5.056       3\n",
              "208  11.84  13.21    0.8521  5.175  2.836  3.598  5.044       3\n",
              "209  12.30  13.34    0.8684  5.243  2.974  5.637  5.063       3\n",
              "\n",
              "[210 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 663
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArD0CFSjCHkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}